--- a/mss_2013_10_31_33895/make/Makefile.common
+++ b/mss_2013_10_31_33895/make/Makefile.common
@@ -659,6 +659,7 @@
  $(OBJ_DIR)$(SEP)rc4algo.o \
  $(OBJ_DIR)$(SEP)rsa.o \
  $(OBJ_DIR)$(SEP)sha1.o \
+ $(OBJ_DIR)$(SEP)sha1-ssse3-amd64.o \
  $(OBJ_DIR)$(SEP)sha256.o \
  $(OBJ_DIR)$(SEP)sha512.o \
  $(OBJ_DIR)$(SEP)three_des.o \
@@ -720,6 +721,7 @@
  $(OBJ_DIR)$(SEP)rsa.o \
  $(OBJ_DIR)$(SEP)sec_key.o \
  $(OBJ_DIR)$(SEP)sha1.o \
+ $(OBJ_DIR)$(SEP)sha1-ssse3-amd64.o \
  $(OBJ_DIR)$(SEP)sha256.o \
  $(OBJ_DIR)$(SEP)sha512.o \
  $(OBJ_DIR)$(SEP)three_des.o \
@@ -741,6 +743,7 @@
  $(OBJ_DIR)$(SEP)md5.o \
  $(OBJ_DIR)$(SEP)hmac.o \
  $(OBJ_DIR)$(SEP)sha1.o \
+ $(OBJ_DIR)$(SEP)sha1-ssse3-amd64.o \
  $(OBJ_DIR)$(SEP)sha256.o \
  $(OBJ_DIR)$(SEP)primeec_mqv.o \
 
@@ -759,6 +762,7 @@
  $(OBJ_DIR)$(SEP)rsa.o \
  $(OBJ_DIR)$(SEP)sec_key.o \
  $(OBJ_DIR)$(SEP)sha1.o \
+ $(OBJ_DIR)$(SEP)sha1-ssse3-amd64.o \
  $(OBJ_DIR)$(SEP)sha256.o \
  $(OBJ_DIR)$(SEP)sha512.o \
 
@@ -773,6 +777,7 @@
  $(OBJ_DIR)$(SEP)md5.o \
  $(OBJ_DIR)$(SEP)md45.o \
  $(OBJ_DIR)$(SEP)sha1.o \
+ $(OBJ_DIR)$(SEP)sha1-ssse3-amd64.o \
 
 CRYPTO_IKE_OBJ = \
  $(OBJ_DIR)$(SEP)aes.o \
@@ -804,6 +809,7 @@
  $(OBJ_DIR)$(SEP)rsa.o \
  $(OBJ_DIR)$(SEP)sec_key.o \
  $(OBJ_DIR)$(SEP)sha1.o \
+ $(OBJ_DIR)$(SEP)sha1-ssse3-amd64.o \
  $(OBJ_DIR)$(SEP)sha256.o \
  $(OBJ_DIR)$(SEP)sha512.o \
  $(OBJ_DIR)$(SEP)three_des.o \
@@ -837,6 +843,7 @@
  $(OBJ_DIR)$(SEP)nil.o \
  $(OBJ_DIR)$(SEP)rc4algo.o \
  $(OBJ_DIR)$(SEP)sha1.o \
+ $(OBJ_DIR)$(SEP)sha1-ssse3-amd64.o \
  $(OBJ_DIR)$(SEP)sha256.o \
  $(OBJ_DIR)$(SEP)sha512.o \
  $(OBJ_DIR)$(SEP)three_des.o \
@@ -870,6 +877,7 @@
  $(OBJ_DIR)$(SEP)rsa.o \
  $(OBJ_DIR)$(SEP)sec_key.o \
  $(OBJ_DIR)$(SEP)sha1.o \
+ $(OBJ_DIR)$(SEP)sha1-ssse3-amd64.o \
  $(OBJ_DIR)$(SEP)sha256.o \
  $(OBJ_DIR)$(SEP)sha512.o \
  $(OBJ_DIR)$(SEP)three_des.o \
@@ -902,6 +910,7 @@
  $(OBJ_DIR)$(SEP)rc4algo.o \
  $(OBJ_DIR)$(SEP)rsa.o \
  $(OBJ_DIR)$(SEP)sha1.o \
+ $(OBJ_DIR)$(SEP)sha1-ssse3-amd64.o \
  $(OBJ_DIR)$(SEP)sha256.o \
  $(OBJ_DIR)$(SEP)sha512.o \
  $(OBJ_DIR)$(SEP)three_des.o \
@@ -937,6 +946,7 @@
  $(OBJ_DIR)$(SEP)rc4algo.o \
  $(OBJ_DIR)$(SEP)rsa.o \
  $(OBJ_DIR)$(SEP)sha1.o \
+ $(OBJ_DIR)$(SEP)sha1-ssse3-amd64.o \
  $(OBJ_DIR)$(SEP)sha256.o \
  $(OBJ_DIR)$(SEP)sha512.o \
  $(OBJ_DIR)$(SEP)des.o \
@@ -980,6 +990,7 @@
  $(OBJ_DIR)$(SEP)rsa.o \
  $(OBJ_DIR)$(SEP)sec_key.o \
  $(OBJ_DIR)$(SEP)sha1.o \
+ $(OBJ_DIR)$(SEP)sha1-ssse3-amd64.o \
  $(OBJ_DIR)$(SEP)sha256.o \
  $(OBJ_DIR)$(SEP)sha512.o \
  $(OBJ_DIR)$(SEP)des.o \
@@ -1000,6 +1011,7 @@
  $(OBJ_DIR)$(SEP)md45.o \
  $(OBJ_DIR)$(SEP)md5.o \
  $(OBJ_DIR)$(SEP)sha1.o \
+ $(OBJ_DIR)$(SEP)sha1-ssse3-amd64.o \
 
 CRYPTO_SCEP_OBJ = \
  $(OBJ_DIR)$(SEP)aes.o \
@@ -1032,6 +1044,7 @@
  $(OBJ_DIR)$(SEP)rsa.o \
  $(OBJ_DIR)$(SEP)sec_key.o \
  $(OBJ_DIR)$(SEP)sha1.o \
+ $(OBJ_DIR)$(SEP)sha1-ssse3-amd64.o \
  $(OBJ_DIR)$(SEP)sha256.o \
  $(OBJ_DIR)$(SEP)sha512.o \
  $(OBJ_DIR)$(SEP)three_des.o \
@@ -1073,6 +1086,7 @@
  $(OBJ_DIR)$(SEP)rsa.o \
  $(OBJ_DIR)$(SEP)sec_key.o \
  $(OBJ_DIR)$(SEP)sha1.o \
+ $(OBJ_DIR)$(SEP)sha1-ssse3-amd64.o \
  $(OBJ_DIR)$(SEP)sha256.o \
  $(OBJ_DIR)$(SEP)sha512.o \
  $(OBJ_DIR)$(SEP)three_des.o \
@@ -1089,6 +1103,7 @@
  $(OBJ_DIR)$(SEP)aes.o \
  $(OBJ_DIR)$(SEP)aes_ctr.o \
  $(OBJ_DIR)$(SEP)sha1.o \
+ $(OBJ_DIR)$(SEP)sha1-ssse3-amd64.o \
  $(OBJ_DIR)$(SEP)aesalgo.o \
  $(OBJ_DIR)$(SEP)gcm.o \
  $(OBJ_DIR)$(SEP)md5.o \
@@ -1126,6 +1141,7 @@
  $(OBJ_DIR)$(SEP)rsa.o \
  $(OBJ_DIR)$(SEP)sec_key.o \
  $(OBJ_DIR)$(SEP)sha1.o \
+ $(OBJ_DIR)$(SEP)sha1-ssse3-amd64.o \
  $(OBJ_DIR)$(SEP)sha256.o \
  $(OBJ_DIR)$(SEP)sha512.o \
  $(OBJ_DIR)$(SEP)three_des.o \
@@ -1181,6 +1197,7 @@
  $(OBJ_DIR)$(SEP)rc4algo.o \
  $(OBJ_DIR)$(SEP)rsa.o \
  $(OBJ_DIR)$(SEP)sha1.o \
+ $(OBJ_DIR)$(SEP)sha1-ssse3-amd64.o \
  $(OBJ_DIR)$(SEP)sha256.o \
  $(OBJ_DIR)$(SEP)sha512.o \
  $(OBJ_DIR)$(SEP)three_des.o \
@@ -2464,6 +2481,9 @@
 $(OBJ_DIR)$(SEP)%.o : $(CRYPTO_SRC_DIR)$(SEP)%.c
 	$(CC) $(CFLAGS) -c -o $@ $<
 
+$(OBJ_DIR)$(SEP)%.o : $(CRYPTO_SRC_DIR)$(SEP)%.S
+	$(CC) $(CFLAGS) -c -o $@ $<
+
 $(OBJ_DIR)$(SEP)%.o : $(CRYPTO_HW_SRC_DIR)$(SEP)%.c
 	$(CC) $(CFLAGS) -c -o $@ $<
 
--- a/mss_2013_10_31_33895/src/crypto/sha1.c
+++ b/mss_2013_10_31_33895/src/crypto/sha1.c
@@ -9,6 +9,8 @@
  *
  */
 
+#define __VC_SHA1__	// undef to completely compile out sha1 sse3 code;
+
 #include "../common/moptions.h"
 #include "../common/mtypes.h"
 #include "../common/mocana.h"
@@ -75,6 +77,35 @@
 /* local prototypes */
 static void sha1_transform(shaDescr *p_shaContext, const ubyte* M);
 
+// init SSE3 state;
+// determines if SSE3 instructions are available on this platform;
+// cpuid checked once for first sha1 context init;
+
+enum sse3_state {
+	SSE3_NOT_INIT = -1,
+	SSE3_NOT_AVAIL = 0,
+	SSE3_USE = 1,
+};
+
+static int use_sse3 = SSE3_NOT_INIT;
+
+extern void
+sse3Init(void)
+{
+	register ubyte4 a, b, c, d;
+
+	a = 1;
+	use_sse3 = SSE3_NOT_AVAIL;
+	asm volatile (
+		"cpuid"
+		: "=a" (a), "=b" (b), "=c" (c), "=d" (d)
+		: "a" (a)
+	);
+	if(c & (1 << 9))
+		use_sse3 = SSE3_USE;
+}
+
+
 /*------------------------------------------------------------------*/
 
 extern MSTATUS
@@ -133,6 +164,13 @@
 {
     MSTATUS status;
 
+    // determine availability of SSE3 on intel;
+
+#ifdef __VC_SHA1__
+    if(use_sse3 < SSE3_NOT_AVAIL)
+        sse3Init();
+#endif // __VC_SHA1__
+
 #if( defined(__ENABLE_MOCANA_FIPS_MODULE__) )
    if (OK != getFIPS_powerupStatus(FIPS_ALGO_SHA1))
         return getFIPS_powerupStatus(FIPS_ALGO_SHA1);
@@ -349,7 +387,7 @@
 
 #if ((!(defined(__SHA1_HARDWARE_HASH__))) || (!(defined(__DISABLE_MOCANA_RNG__))))
 static void
-sha1_transform(SW_SHA1_CTX *p_shaContext, const ubyte* M)
+sha1_transform_sw(SW_SHA1_CTX *p_shaContext, const ubyte* M)
 {
 #ifdef __ENABLE_MOCANA_MINIMUM_STACK__
     ubyte4 *W = p_shaContext->W;
@@ -461,6 +499,20 @@
     p_shaContext->hashBlocks[4] += E;
 }
 
+
+static void
+sha1_transform(SW_SHA1_CTX *p_shaContext, const ubyte* M)
+{
+#ifdef __VC_SHA1__
+	extern void sha1_transform_amd64_ssse3(void *state, const ubyte *m);
+	if(use_sse3)
+		sha1_transform_amd64_ssse3(p_shaContext->hashBlocks, M);
+	else
+#endif // __VC_SHA1__
+		sha1_transform_sw(p_shaContext, M);
+}
+	
+
 /*------------------------------------------------------------------*/
 
 
--- /dev/null
+++ b/mss_2013_10_31_33895/src/crypto/sha1-ssse3-amd64.S
@@ -0,0 +1,374 @@
+/* sha1-ssse3-amd64.S - Intel SSSE3 accelerated SHA-1 transform function
+ * Copyright Â© 2013 Jussi Kivilinna <jussi.kivilinna@iki.fi>
+ *
+ * Based on sha1.c:
+ *  Copyright (C) 1998, 2001, 2002, 2003, 2008 Free Software Foundation, Inc.
+ *
+ * This file is part of Libgcrypt.
+ *
+ * Libgcrypt is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * Libgcrypt is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this program; if not, see <http://www.gnu.org/licenses/>.
+ */
+
+/*
+ * Intel SSSE3 accelerated SHA-1 implementation based on white paper:
+ *  "Improving the Performance of the Secure Hash Algorithm (SHA-1)"
+ *  http://software.intel.com/en-us/articles/improving-the-performance-of-the-secure-hash-algorithm-1
+ * velocloud: modified for mocana inclusion;
+ */
+
+#ifdef __x86_64__
+
+#ifdef __PIC__
+#  define RIP (%rip)
+#else
+#  define RIP
+#endif
+
+
+/* Context structure */
+
+#define state_h0 0
+#define state_h1 4
+#define state_h2 8
+#define state_h3 12
+#define state_h4 16
+
+
+/* Constants */
+
+.data
+#define K1  0x5A827999
+#define K2  0x6ED9EBA1
+#define K3  0x8F1BBCDC
+#define K4  0xCA62C1D6
+.align 16
+.LK_XMM:
+.LK1:	.long K1, K1, K1, K1
+.LK2:	.long K2, K2, K2, K2
+.LK3:	.long K3, K3, K3, K3
+.LK4:	.long K4, K4, K4, K4
+
+.Lbswap_shufb_ctl:
+	.long 0x00010203, 0x04050607, 0x08090a0b, 0x0c0d0e0f
+
+
+/* Register macros */
+
+#define RSTATE %r8
+#define RDATA %r9
+#define ROLDSTACK %r10
+
+#define a %eax
+#define b %ebx
+#define c %ecx
+#define d %edx
+#define e %edi
+
+#define RT0 %esi
+#define RT1 %ebp
+
+#define Wtmp0 %xmm0
+#define Wtmp1 %xmm1
+
+#define W0 %xmm2
+#define W1 %xmm3
+#define W2 %xmm4
+#define W3 %xmm5
+#define W4 %xmm6
+#define W5 %xmm7
+#define W6 %xmm8
+#define W7 %xmm9
+
+#define BSWAP_REG %xmm10
+
+
+/* Round function macros. */
+
+#define WK(i) (((i) & 15) * 4)(%rsp)
+
+#define R_F1(a,b,c,d,e,i) \
+	movl c, RT0; \
+	addl WK(i), e; \
+	xorl d, RT0; \
+	movl a, RT1; \
+	andl b, RT0; \
+	roll $30, b; \
+	xorl d, RT0; \
+	leal (RT0,e), e; \
+	roll $5, RT1; \
+	addl RT1, e;
+
+#define R_F2(a,b,c,d,e,i) \
+	movl c, RT0; \
+	addl WK(i), e; \
+	xorl b, RT0; \
+	roll $30, b; \
+	xorl d, RT0; \
+	movl a, RT1; \
+	leal (RT0,e), e; \
+	roll $5, RT1; \
+	addl RT1, e;
+
+#define R_F3(a,b,c,d,e,i) \
+	movl c, RT0; \
+	movl b, RT1; \
+	xorl b, RT0; \
+	andl c, RT1; \
+	andl d, RT0; \
+	addl RT1, e; \
+	addl WK(i), e; \
+	roll $30, b; \
+	movl a, RT1; \
+	leal (RT0,e), e; \
+	roll $5, RT1; \
+	addl RT1, e;
+
+#define R_F4(a,b,c,d,e,i) R_F2(a,b,c,d,e,i)
+
+#define R(a,b,c,d,e,f,i) \
+	R_##f(a,b,c,d,e,i)
+
+
+/* Input expansion macros. */
+
+#define W_PRECALC_00_15_0(i, W, tmp0) \
+	movdqu (4*(i))(RDATA), tmp0;
+
+#define W_PRECALC_00_15_1(i, W, tmp0) \
+	pshufb BSWAP_REG, tmp0; \
+	movdqa tmp0, W;
+
+#define W_PRECALC_00_15_2(i, W, tmp0) \
+	paddd (.LK_XMM + ((i)/20)*16) RIP, tmp0;
+
+#define W_PRECALC_00_15_3(i, W, tmp0) \
+	movdqa tmp0, WK(i&~3);
+
+#define W_PRECALC_16_31_0(i, W, W_m04, W_m08, W_m12, W_m16, tmp0, tmp1) \
+	movdqa W_m12, W; \
+	palignr $8, W_m16, W; \
+	movdqa W_m04, tmp0; \
+	psrldq $4, tmp0; \
+	pxor W_m08, W;
+
+#define W_PRECALC_16_31_1(i, W, W_m04, W_m08, W_m12, W_m16, tmp0, tmp1) \
+	pxor W_m16, tmp0; \
+	pxor tmp0, W; \
+	movdqa W, tmp1; \
+	movdqa W, tmp0; \
+	pslldq $12, tmp1;
+
+#define W_PRECALC_16_31_2(i, W, W_m04, W_m08, W_m12, W_m16, tmp0, tmp1) \
+	psrld $31, W; \
+	pslld $1, tmp0; \
+	por W, tmp0; \
+	movdqa tmp1, W; \
+	psrld $30, tmp1; \
+	pslld $2, W;
+
+#define W_PRECALC_16_31_3(i, W, W_m04, W_m08, W_m12, W_m16, tmp0, tmp1) \
+	pxor W, tmp0; \
+	pxor tmp1, tmp0; \
+	movdqa tmp0, W; \
+	paddd (.LK_XMM + ((i)/20)*16) RIP, tmp0; \
+	movdqa tmp0, WK((i)&~3);
+
+#define W_PRECALC_32_79_0(i, W, W_m04, W_m08, W_m12, W_m16, W_m20, W_m24, W_m28, tmp0) \
+	movdqa W_m04, tmp0; \
+	pxor W_m28, W; \
+	palignr $8, W_m08, tmp0;
+
+#define W_PRECALC_32_79_1(i, W, W_m04, W_m08, W_m12, W_m16, W_m20, W_m24, W_m28, tmp0) \
+	pxor W_m16, W; \
+	pxor tmp0, W; \
+	movdqa W, tmp0;
+
+#define W_PRECALC_32_79_2(i, W, W_m04, W_m08, W_m12, W_m16, W_m20, W_m24, W_m28, tmp0) \
+	psrld $30, W; \
+	pslld $2, tmp0; \
+	por W, tmp0;
+
+#define W_PRECALC_32_79_3(i, W, W_m04, W_m08, W_m12, W_m16, W_m20, W_m24, W_m28, tmp0) \
+	movdqa tmp0, W; \
+	paddd (.LK_XMM + ((i)/20)*16) RIP, tmp0; \
+	movdqa tmp0, WK((i)&~3);
+
+#define CLEAR_REG(reg) pxor reg, reg;
+
+
+/*
+ * Transform 64 bytes (16 32-bit words) at DATA.
+ *
+ * unsigned int
+ * sha1_transform_amd64_ssse3 (void *ctx, const unsigned char *data)
+ */
+.text
+.globl sha1_transform_amd64_ssse3
+.type sha1_transform_amd64_ssse3,@function
+.align 16
+sha1_transform_amd64_ssse3:
+  /* input:
+   *	%rdi: ctx, CTX
+   *	%rsi: data (64 bytes)
+   *	%rdx: ...
+   */
+
+  movq %rdi, RSTATE;
+  movq %rsi, RDATA;
+  pushq %rbx;
+  pushq %rbp;
+
+  movq %rsp, ROLDSTACK;
+
+  subq $(16*4), %rsp;
+  andq $(~31), %rsp;
+
+  /* Get the values of the chaining variables. */
+  movl state_h0(RSTATE), a;
+  movl state_h1(RSTATE), b;
+  movl state_h2(RSTATE), c;
+  movl state_h3(RSTATE), d;
+  movl state_h4(RSTATE), e;
+
+  movdqa .Lbswap_shufb_ctl RIP, BSWAP_REG;
+
+  /* Precalc 0-15. */
+  W_PRECALC_00_15_0(0, W0, Wtmp0);
+  W_PRECALC_00_15_1(1, W0, Wtmp0);
+  W_PRECALC_00_15_2(2, W0, Wtmp0);
+  W_PRECALC_00_15_3(3, W0, Wtmp0);
+  W_PRECALC_00_15_0(4, W7, Wtmp0);
+  W_PRECALC_00_15_1(5, W7, Wtmp0);
+  W_PRECALC_00_15_2(6, W7, Wtmp0);
+  W_PRECALC_00_15_3(7, W7, Wtmp0);
+  W_PRECALC_00_15_0(8, W6, Wtmp0);
+  W_PRECALC_00_15_1(9, W6, Wtmp0);
+  W_PRECALC_00_15_2(10, W6, Wtmp0);
+  W_PRECALC_00_15_3(11, W6, Wtmp0);
+  W_PRECALC_00_15_0(12, W5, Wtmp0);
+  W_PRECALC_00_15_1(13, W5, Wtmp0);
+  W_PRECALC_00_15_2(14, W5, Wtmp0);
+  W_PRECALC_00_15_3(15, W5, Wtmp0);
+
+  /* Transform 0-15 + Precalc 16-31. */
+  R( a, b, c, d, e, F1,  0 ); W_PRECALC_16_31_0(16, W4, W5, W6, W7, W0, Wtmp0, Wtmp1);
+  R( e, a, b, c, d, F1,  1 ); W_PRECALC_16_31_1(17, W4, W5, W6, W7, W0, Wtmp0, Wtmp1);
+  R( d, e, a, b, c, F1,  2 ); W_PRECALC_16_31_2(18, W4, W5, W6, W7, W0, Wtmp0, Wtmp1);
+  R( c, d, e, a, b, F1,  3 ); W_PRECALC_16_31_3(19, W4, W5, W6, W7, W0, Wtmp0, Wtmp1);
+  R( b, c, d, e, a, F1,  4 ); W_PRECALC_16_31_0(20, W3, W4, W5, W6, W7, Wtmp0, Wtmp1);
+  R( a, b, c, d, e, F1,  5 ); W_PRECALC_16_31_1(21, W3, W4, W5, W6, W7, Wtmp0, Wtmp1);
+  R( e, a, b, c, d, F1,  6 ); W_PRECALC_16_31_2(22, W3, W4, W5, W6, W7, Wtmp0, Wtmp1);
+  R( d, e, a, b, c, F1,  7 ); W_PRECALC_16_31_3(23, W3, W4, W5, W6, W7, Wtmp0, Wtmp1);
+  R( c, d, e, a, b, F1,  8 ); W_PRECALC_16_31_0(24, W2, W3, W4, W5, W6, Wtmp0, Wtmp1);
+  R( b, c, d, e, a, F1,  9 ); W_PRECALC_16_31_1(25, W2, W3, W4, W5, W6, Wtmp0, Wtmp1);
+  R( a, b, c, d, e, F1, 10 ); W_PRECALC_16_31_2(26, W2, W3, W4, W5, W6, Wtmp0, Wtmp1);
+  R( e, a, b, c, d, F1, 11 ); W_PRECALC_16_31_3(27, W2, W3, W4, W5, W6, Wtmp0, Wtmp1);
+  R( d, e, a, b, c, F1, 12 ); W_PRECALC_16_31_0(28, W1, W2, W3, W4, W5, Wtmp0, Wtmp1);
+  R( c, d, e, a, b, F1, 13 ); W_PRECALC_16_31_1(29, W1, W2, W3, W4, W5, Wtmp0, Wtmp1);
+  R( b, c, d, e, a, F1, 14 ); W_PRECALC_16_31_2(30, W1, W2, W3, W4, W5, Wtmp0, Wtmp1);
+  R( a, b, c, d, e, F1, 15 ); W_PRECALC_16_31_3(31, W1, W2, W3, W4, W5, Wtmp0, Wtmp1);
+
+  /* Transform 16-63 + Precalc 32-79. */
+  R( e, a, b, c, d, F1, 16 ); W_PRECALC_32_79_0(32, W0, W1, W2, W3, W4, W5, W6, W7, Wtmp0);
+  R( d, e, a, b, c, F1, 17 ); W_PRECALC_32_79_1(33, W0, W1, W2, W3, W4, W5, W6, W7, Wtmp0);
+  R( c, d, e, a, b, F1, 18 ); W_PRECALC_32_79_2(34, W0, W1, W2, W3, W4, W5, W6, W7, Wtmp0);
+  R( b, c, d, e, a, F1, 19 ); W_PRECALC_32_79_3(35, W0, W1, W2, W3, W4, W5, W6, W7, Wtmp0);
+  R( a, b, c, d, e, F2, 20 ); W_PRECALC_32_79_0(36, W7, W0, W1, W2, W3, W4, W5, W6, Wtmp0);
+  R( e, a, b, c, d, F2, 21 ); W_PRECALC_32_79_1(37, W7, W0, W1, W2, W3, W4, W5, W6, Wtmp0);
+  R( d, e, a, b, c, F2, 22 ); W_PRECALC_32_79_2(38, W7, W0, W1, W2, W3, W4, W5, W6, Wtmp0);
+  R( c, d, e, a, b, F2, 23 ); W_PRECALC_32_79_3(39, W7, W0, W1, W2, W3, W4, W5, W6, Wtmp0);
+  R( b, c, d, e, a, F2, 24 ); W_PRECALC_32_79_0(40, W6, W7, W0, W1, W2, W3, W4, W5, Wtmp0);
+  R( a, b, c, d, e, F2, 25 ); W_PRECALC_32_79_1(41, W6, W7, W0, W1, W2, W3, W4, W5, Wtmp0);
+  R( e, a, b, c, d, F2, 26 ); W_PRECALC_32_79_2(42, W6, W7, W0, W1, W2, W3, W4, W5, Wtmp0);
+  R( d, e, a, b, c, F2, 27 ); W_PRECALC_32_79_3(43, W6, W7, W0, W1, W2, W3, W4, W5, Wtmp0);
+  R( c, d, e, a, b, F2, 28 ); W_PRECALC_32_79_0(44, W5, W6, W7, W0, W1, W2, W3, W4, Wtmp0);
+  R( b, c, d, e, a, F2, 29 ); W_PRECALC_32_79_1(45, W5, W6, W7, W0, W1, W2, W3, W4, Wtmp0);
+  R( a, b, c, d, e, F2, 30 ); W_PRECALC_32_79_2(46, W5, W6, W7, W0, W1, W2, W3, W4, Wtmp0);
+  R( e, a, b, c, d, F2, 31 ); W_PRECALC_32_79_3(47, W5, W6, W7, W0, W1, W2, W3, W4, Wtmp0);
+  R( d, e, a, b, c, F2, 32 ); W_PRECALC_32_79_0(48, W4, W5, W6, W7, W0, W1, W2, W3, Wtmp0);
+  R( c, d, e, a, b, F2, 33 ); W_PRECALC_32_79_1(49, W4, W5, W6, W7, W0, W1, W2, W3, Wtmp0);
+  R( b, c, d, e, a, F2, 34 ); W_PRECALC_32_79_2(50, W4, W5, W6, W7, W0, W1, W2, W3, Wtmp0);
+  R( a, b, c, d, e, F2, 35 ); W_PRECALC_32_79_3(51, W4, W5, W6, W7, W0, W1, W2, W3, Wtmp0);
+  R( e, a, b, c, d, F2, 36 ); W_PRECALC_32_79_0(52, W3, W4, W5, W6, W7, W0, W1, W2, Wtmp0);
+  R( d, e, a, b, c, F2, 37 ); W_PRECALC_32_79_1(53, W3, W4, W5, W6, W7, W0, W1, W2, Wtmp0);
+  R( c, d, e, a, b, F2, 38 ); W_PRECALC_32_79_2(54, W3, W4, W5, W6, W7, W0, W1, W2, Wtmp0);
+  R( b, c, d, e, a, F2, 39 ); W_PRECALC_32_79_3(55, W3, W4, W5, W6, W7, W0, W1, W2, Wtmp0);
+  R( a, b, c, d, e, F3, 40 ); W_PRECALC_32_79_0(56, W2, W3, W4, W5, W6, W7, W0, W1, Wtmp0);
+  R( e, a, b, c, d, F3, 41 ); W_PRECALC_32_79_1(57, W2, W3, W4, W5, W6, W7, W0, W1, Wtmp0);
+  R( d, e, a, b, c, F3, 42 ); W_PRECALC_32_79_2(58, W2, W3, W4, W5, W6, W7, W0, W1, Wtmp0);
+  R( c, d, e, a, b, F3, 43 ); W_PRECALC_32_79_3(59, W2, W3, W4, W5, W6, W7, W0, W1, Wtmp0);
+  R( b, c, d, e, a, F3, 44 ); W_PRECALC_32_79_0(60, W1, W2, W3, W4, W5, W6, W7, W0, Wtmp0);
+  R( a, b, c, d, e, F3, 45 ); W_PRECALC_32_79_1(61, W1, W2, W3, W4, W5, W6, W7, W0, Wtmp0);
+  R( e, a, b, c, d, F3, 46 ); W_PRECALC_32_79_2(62, W1, W2, W3, W4, W5, W6, W7, W0, Wtmp0);
+  R( d, e, a, b, c, F3, 47 ); W_PRECALC_32_79_3(63, W1, W2, W3, W4, W5, W6, W7, W0, Wtmp0);
+  R( c, d, e, a, b, F3, 48 ); W_PRECALC_32_79_0(64, W0, W1, W2, W3, W4, W5, W6, W7, Wtmp0);
+  R( b, c, d, e, a, F3, 49 ); W_PRECALC_32_79_1(65, W0, W1, W2, W3, W4, W5, W6, W7, Wtmp0);
+  R( a, b, c, d, e, F3, 50 ); W_PRECALC_32_79_2(66, W0, W1, W2, W3, W4, W5, W6, W7, Wtmp0);
+  R( e, a, b, c, d, F3, 51 ); W_PRECALC_32_79_3(67, W0, W1, W2, W3, W4, W5, W6, W7, Wtmp0);
+  R( d, e, a, b, c, F3, 52 ); W_PRECALC_32_79_0(68, W7, W0, W1, W2, W3, W4, W5, W6, Wtmp0);
+  R( c, d, e, a, b, F3, 53 ); W_PRECALC_32_79_1(69, W7, W0, W1, W2, W3, W4, W5, W6, Wtmp0);
+  R( b, c, d, e, a, F3, 54 ); W_PRECALC_32_79_2(70, W7, W0, W1, W2, W3, W4, W5, W6, Wtmp0);
+  R( a, b, c, d, e, F3, 55 ); W_PRECALC_32_79_3(71, W7, W0, W1, W2, W3, W4, W5, W6, Wtmp0);
+  R( e, a, b, c, d, F3, 56 ); W_PRECALC_32_79_0(72, W6, W7, W0, W1, W2, W3, W4, W5, Wtmp0);
+  R( d, e, a, b, c, F3, 57 ); W_PRECALC_32_79_1(73, W6, W7, W0, W1, W2, W3, W4, W5, Wtmp0);
+  R( c, d, e, a, b, F3, 58 ); W_PRECALC_32_79_2(74, W6, W7, W0, W1, W2, W3, W4, W5, Wtmp0);
+  R( b, c, d, e, a, F3, 59 ); W_PRECALC_32_79_3(75, W6, W7, W0, W1, W2, W3, W4, W5, Wtmp0);
+  R( a, b, c, d, e, F4, 60 ); W_PRECALC_32_79_0(76, W5, W6, W7, W0, W1, W2, W3, W4, Wtmp0);
+  R( e, a, b, c, d, F4, 61 ); W_PRECALC_32_79_1(77, W5, W6, W7, W0, W1, W2, W3, W4, Wtmp0);
+  R( d, e, a, b, c, F4, 62 ); W_PRECALC_32_79_2(78, W5, W6, W7, W0, W1, W2, W3, W4, Wtmp0);
+  R( c, d, e, a, b, F4, 63 ); W_PRECALC_32_79_3(79, W5, W6, W7, W0, W1, W2, W3, W4, Wtmp0);
+
+  /* Transform 64-79 + Clear XMM registers. */
+  R( b, c, d, e, a, F4, 64 ); CLEAR_REG(BSWAP_REG);
+  R( a, b, c, d, e, F4, 65 ); CLEAR_REG(Wtmp0);
+  R( e, a, b, c, d, F4, 66 ); CLEAR_REG(Wtmp1);
+  R( d, e, a, b, c, F4, 67 ); CLEAR_REG(W0);
+  R( c, d, e, a, b, F4, 68 ); CLEAR_REG(W1);
+  R( b, c, d, e, a, F4, 69 ); CLEAR_REG(W2);
+  R( a, b, c, d, e, F4, 70 ); CLEAR_REG(W3);
+  R( e, a, b, c, d, F4, 71 ); CLEAR_REG(W4);
+  R( d, e, a, b, c, F4, 72 ); CLEAR_REG(W5);
+  R( c, d, e, a, b, F4, 73 ); CLEAR_REG(W6);
+  R( b, c, d, e, a, F4, 74 ); CLEAR_REG(W7);
+  R( a, b, c, d, e, F4, 75 );
+  R( e, a, b, c, d, F4, 76 );
+  R( d, e, a, b, c, F4, 77 );
+  R( c, d, e, a, b, F4, 78 );
+  R( b, c, d, e, a, F4, 79 );
+
+  /* Update the chaining variables. */
+  addl state_h0(RSTATE), a;
+  addl state_h1(RSTATE), b;
+  addl state_h2(RSTATE), c;
+  addl state_h3(RSTATE), d;
+  addl state_h4(RSTATE), e;
+
+  movl a, state_h0(RSTATE);
+  movl b, state_h1(RSTATE);
+  movl c, state_h2(RSTATE);
+  movl d, state_h3(RSTATE);
+  movl e, state_h4(RSTATE);
+
+  movq ROLDSTACK, %rsp;
+
+  popq %rbp;
+  popq %rbx;
+
+  /* burn_stack */
+  movl $(16*4 + 2*8 + 31), %eax;
+
+  ret;
+
+#endif // __x86_64__
+
--- a/vc-sha-test/Makefile
+++ b/vc-sha-test/Makefile
@@ -0,0 +1,16 @@
+
+MOC = ../mss_2013_10_31_33895
+
+INCL = -I$(MOC)/src
+
+DEFS += -D__RTOS_LINUX__
+DEFS += -D__ENABLE_MOCANA_64_BIT__=
+DEFS += -D__IKE_MULTI_HOMING__=
+DEFS += -D__ENABLE_IPSEC_NAT_T__=
+DEFS += -D__ENABLE_IPSEC_COOKIE__=
+
+LIBS = -lcrypto $(MOC)/bin/libikeipsec.a
+
+sha-test: sha-test.c
+	cc -o $@ -O $(DEFS) $(INCL) $< $(LIBS)
+
--- a/vc-sha-test/sha-test.c
+++ b/vc-sha-test/sha-test.c
@@ -0,0 +1,202 @@
+// aes speed test;
+// tests aesEncrypt() and aesDecrypt() functions;
+// to prove to ourselves that the aesni code works and is faster;
+
+#include <sys/types.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <stdint.h>
+#include <openssl/sha.h>
+
+#include "common/moptions.h"
+#include "common/mdefs.h"
+#include "common/mtypes.h"
+#include "common/merrors.h"
+#include "common/mstdlib.h"
+#include "common/mrtos.h"
+#include "ipsec/ipsec.h"
+#include "ipsec/ipsec_defs.h"
+#include "ipsec/ipsec_protos.h"
+#include "ipsec/ipsecconf.h"
+#include "ipsec/ipseckey.h"
+#include "crypto/hw_accel.h"
+#include "crypto/sha1.h"
+
+// have a large buffer for an all-cache hit and miss sweep;
+// sweep for 64,128,...,2048 byte blocks;
+// assume the max L3 is 4MB, so use 100x that for efficient misses;
+
+#define PBUF_SIZE 1024*1024*400
+
+u_char pbuf[PBUF_SIZE];
+
+// for random addresses use a table of random indicies;
+
+#define PKT_SIZE_MIN 64
+#define PKT_SIZE_MAX 2048
+#define MAX_PKT_IDX (PBUF_SIZE / PKT_SIZE_MIN)
+
+u_int pbuf_idx[MAX_PKT_IDX];
+
+// packet sizes for profile;
+// aes blocks are 16 byte, so should be multiple of that;
+
+u_int pkt_sizes[] = { 64, 128, 256, 512, 1024, 1600, 0 };
+
+// all hashes;
+
+u_char hashes[MAX_PKT_IDX * 32];
+
+// compute sha1 over block;
+// make printable;
+
+char *
+sha1_buf(u_char *p, u_int len)
+{
+	char *hp;
+	u_int i;
+	u_char md[20];
+	static char hs[64];
+
+	SHA1(p, len, md);
+	for(hp = hs, i = 0; i < 20; i++, hp += 2)
+		sprintf(hp, "%02x", md[i]);
+	return(hs);
+}
+
+// dump first N packet hashes;
+
+void
+dump_pkt_sha1(u_int idx, u_int pkt_size, u_char *pt, u_char *ct)
+{
+	if(idx < 10) {
+		printf("  %s", sha1_buf(pt, pkt_size));
+		printf(" %s\n", sha1_buf(ct, pkt_size));
+	}
+}
+
+// stride tests;
+// both ciphertext and plaintext in linear order,
+// for maximum cache effect;
+
+// aes encrypt stride;
+
+void
+sha1_stride(u_int pkt_size, u_int npkts)
+{
+	u_char *dp, *ep, *hp;
+	u_int n;
+	struct timeval t0, t1;
+	uint64_t dt;
+	double mbs;
+	char *hs;
+	shaDescr ctx;
+
+	dp = pbuf;
+	ep = pbuf + (pkt_size * npkts);
+	hp = hashes;
+
+	gettimeofday(&t0, NULL);
+	for(n = 0; dp < ep; n++) {
+		SHA1_initDigest(&ctx);
+		SHA1_updateDigest(&ctx, dp, pkt_size);
+		SHA1_finalDigest(&ctx, hp);
+		dp += pkt_size;
+		hp += 20;
+	}
+	gettimeofday(&t1, NULL);
+
+	hs = sha1_buf(pbuf, npkts * 20);
+
+	dt = (t1.tv_sec * 1000000ULL) + t1.tv_usec
+		- (t0.tv_sec * 1000000ULL) - t0.tv_usec;
+	mbs = (double)(n * pkt_size) / (double)dt;
+	printf(" %s: %u %ub packets in %lu usec, %f MB/s, %s\n",
+		__func__, n, pkt_size, dt, mbs, hs);
+}
+
+// random tests;
+// both ciphertext and plaintext in random order,
+// for maximum cache misses;
+
+// aes encrypt stride;
+
+#ifdef XXX
+void
+sha1_random(u_int pkt_size, u_int npkts)
+{
+	sbyte4 nr = (ks >> 5) + 6;
+	u_int *idxp, *ep;
+	u_char *ct, *pt;
+	u_int n, off;
+	struct timeval t0, t1;
+	uint64_t dt;
+	double mbs;
+	char *hs;
+
+	AESALGO_makeAesKey(ctx, ks, key, 1, MODE_NONE);
+	//dump_keys();
+
+	idxp = pbuf_idx;
+	ep = idxp + npkts;
+
+	gettimeofday(&t0, NULL);
+	for(n = 0; idxp < ep; n++, idxp += 2) {
+		pt = pbuf + idxp[0];
+		ct = pbuf + idxp[1];
+		for(off = 0; off < pkt_size; off += 16)
+			aesEncrypt(ctx->rk, nr, pt + off, ct + off);
+	}
+	gettimeofday(&t1, NULL);
+
+	hs = sha1_buf(pbuf, pkt_size * npkts);
+
+	dt = (t1.tv_sec * 1000000ULL) + t1.tv_usec
+		- (t0.tv_sec * 1000000ULL) - t0.tv_usec;
+	mbs = (double)(n * pkt_size) / (double)dt;
+	printf(" %s: k%u %u %ub packets in %lu usec, %f MB/s, %s\n",
+		__func__, ks, n, pkt_size, dt, mbs, hs);
+}
+#endif
+
+// main entry;
+
+int
+main(int argc, char **argv)
+{
+	u_char *p;
+	u_int *idxp, *sizep;
+	u_int pkt_size, npkts;
+	u_int *ksp, ks;
+
+	// get random seed;
+
+	srandom(0x1);
+
+	// fill buffer with randoms;
+	// we shouldn't start with a 0-fill buffer, as code could have holes;
+
+	printf("filling buffer randoms\n");
+	for(p = pbuf; p < pbuf + sizeof(pbuf); p += 4)
+		*((u_int *)p) = random();
+
+	// run tests for all the pkt sizes;
+
+	printf("starting tests\n");
+	for(sizep = pkt_sizes; pkt_size = *sizep; sizep++) {
+		npkts = sizeof(pbuf) / pkt_size;
+
+		// make new pkt indicies for each test;
+
+		for(idxp = pbuf_idx; idxp < pbuf_idx + npkts; idxp++)
+			*idxp = random() % npkts;
+
+		// run tests for each key size;
+
+		sha1_stride(pkt_size, npkts);
+		//sha1_random(pkt_size, npkts);
+	}
+
+	return(0);
+}
+
